---
description: Guidelines for interacting with the unified AI service layer.
globs: scripts/modules/ai-services-unified.js, scripts/modules/task-manager/*.js, scripts/modules/commands.js
alwaysApply: false
---

# AI Services Layer Guidelines

This document outlines the architecture and usage patterns for interacting with Large Language Models (LLMs) via LM-Tasker's unified AI service layer (`ai-services-unified.js`). The AI service layer is exclusively used for PRD parsing operations. The goal is to centralize configuration, provider selection, API key management, fallback logic, and error handling for PRD-to-tasks conversion.

**AI Usage Scope:**
*   **PRD Parsing Only**: AI services are used exclusively for parsing Product Requirements Documents (PRDs) and converting them to tasks
*   **Manual Task Management**: All other task operations (add, update, modify) are performed manually through CLI/MCP tools
*   **No AI Task Operations**: The AI service layer is NOT used for task creation, updates, or management outside of PRD parsing

**Core Components:**

*   **Configuration (`.lmtaskerconfig` & [`config-manager.js`](mdc:scripts/modules/config-manager.js)):**
    *   Defines the AI provider and model ID for different **roles** (`main`, `research`, `fallback`) used in PRD parsing.
    *   Stores parameters like `maxTokens` and `temperature` per role for PRD parsing operations.
    *   Managed via the `lm-tasker models --setup` CLI command.
    *   [`config-manager.js`](mdc:scripts/modules/config-manager.js) provides **getters** (e.g., `getMainProvider()`, `getParametersForRole()`) to access these settings. Core logic should **only** use these getters for *non-AI related application logic* (e.g., `getDefaultSubtasks`). The unified service fetches necessary AI parameters internally based on the `role`.
    *   **API keys** are **NOT** stored here; they are resolved via `resolveEnvVariable` (in [`utils.js`](mdc:scripts/modules/utils.js)) from `.env` (for CLI) or the MCP `session.env` object (for MCP calls). See [`utilities.mdc`](mdc:.cursor/rules/utilities.mdc) and [`dev_workflow.mdc`](mdc:.cursor/rules/dev_workflow.mdc).

*   **Unified Service (`ai-services-unified.js`):**
    *   Exports primary interaction functions: `generateTextService`, `generateObjectService`. (Note: `streamTextService` exists but has known reliability issues with some providers/payloads).
    *   Contains the core `_unifiedServiceRunner` logic.
    *   Internally uses `config-manager.js` getters to determine the provider/model/parameters based on the requested `role`.
    *   Implements the **fallback sequence** (e.g., main -> fallback -> research) if the primary provider/model fails during PRD parsing.
    *   Constructs the `messages` array required by the Vercel AI SDK.
    *   Implements **retry logic** for specific API errors (`_attemptProviderCallWithRetries`).
    *   Resolves API keys automatically via `_resolveApiKey` (using `resolveEnvVariable`).
    *   Maps requests to the correct provider implementation (in `src/ai-providers/`) via `PROVIDER_FUNCTIONS`.
    *   Returns a structured object containing the primary AI result (`mainResult`) and telemetry data (`telemetryData`). See [`telemetry.mdc`](mdc:.cursor/rules/telemetry.mdc) for details on how this telemetry data is propagated and handled.

*   **Provider Implementations (`src/ai-providers/*.js`):**
    *   Contain provider-specific wrappers around Vercel AI SDK functions (`generateText`, `generateObject`).

**Usage Pattern (from PRD Parsing Logic like `parse-prd.js`):**

1.  **Import Service:** Import `generateTextService` or `generateObjectService` from `../ai-services-unified.js`.
    ```javascript
    // Preferred for PRD parsing (especially with complex JSON)
    import { generateTextService } from '../ai-services-unified.js';

    // Use if structured output is reliable for the specific use case
    // import { generateObjectService } from '../ai-services-unified.js';
    ```

2.  **Prepare Parameters:** Construct the parameters object for the service call.
    *   `role`: **Required.** `'main'`, `'research'`, or `'fallback'`. Determines the initial provider/model/parameters used by the unified service for PRD parsing.
    *   `session`: **Required if called from MCP context.** Pass the `session` object received by the direct function wrapper. The unified service uses `session.env` to find API keys.
    *   `systemPrompt`: Your system instruction string for PRD parsing.
    *   `prompt`: The user message string containing the PRD content (can be long, include stringified data, etc.).
    *   (For `generateObjectService` only): `schema` (Zod schema), `objectName`.

3.  **Call Service:** Use `await` to call the service function for PRD parsing.
    ```javascript
    // Example using generateTextService for PRD parsing (most common)
    try {
        const resultText = await generateTextService({
            role: useResearch ? 'research' : 'main', // Determine role based on logic
            session: context.session, // Pass session from context object
            systemPrompt: "You are assisting with transforming a PRD into tasks...",
            prompt: prdContent
        });
        // Process the raw text response (e.g., parse JSON, use directly)
        // ...
    } catch (error) {
        // Handle errors thrown by the unified service (if all fallbacks/retries fail)
        report('error', `PRD parsing AI service call failed: ${error.message}`);
        throw error;
    }

    // Example using generateObjectService for PRD parsing (use cautiously)
    try {
        const resultObject = await generateObjectService({
            role: 'main',
            session: context.session,
            schema: tasksSchema,
            objectName: 'parsedTasks',
            systemPrompt: "You are assisting with transforming a PRD into tasks...",
            prompt: prdContent
        });
        // resultObject is already a validated JS object
        // ...
    } catch (error) {
        report('error', `PRD parsing AI service call failed: ${error.message}`);
        throw error;
    }
    ```

4.  **Handle Results/Errors:** Process the returned text/object or handle errors thrown by the unified service layer.

**Key Implementation Rules & Gotchas:**

*   ✅ **DO**: Centralize **all** LLM calls for PRD parsing through `generateTextService` or `generateObjectService`.
*   ✅ **DO**: Determine the appropriate `role` (`main`, `research`, `fallback`) in your PRD parsing logic and pass it to the service.
*   ✅ **DO**: Pass the `session` object (received in the `context` parameter, especially from direct function wrappers) to the service call when in MCP context.
*   ✅ **DO**: Ensure API keys are correctly configured in `.env` (for CLI) or `.cursor/mcp.json` (for MCP).
*   ✅ **DO**: Ensure `.lmtaskerconfig` exists and has valid provider/model IDs for the roles you intend to use (manage via `lm-tasker models --setup`).
*   ✅ **DO**: Use `generateTextService` and implement robust manual JSON parsing (with Zod validation *after* parsing) when structured output is needed for PRD parsing, as `generateObjectService` has shown unreliability with some providers/schemas.
*   ✅ **DO**: Only use AI services for PRD parsing operations - all other task management is manual.
*   ❌ **DON'T**: Import or call anything from the old `ai-services.js`, `ai-client-factory.js`, or `ai-client-utils.js` files.
*   ❌ **DON'T**: Initialize AI clients (Anthropic, Perplexity, etc.) directly within core logic (`task-manager/`) or MCP direct functions.
*   ❌ **DON'T**: Fetch AI-specific parameters (model ID, max tokens, temp) using `config-manager.js` getters *for the AI call*. Pass the `role` instead.
*   ❌ **DON'T**: Implement fallback or retry logic outside `ai-services-unified.js`.
*   ❌ **DON'T**: Handle API key resolution outside the service layer (it uses `utils.js` internally).
*   ❌ **DON'T**: Use AI services for task creation, updates, or management operations - these are manual operations only.
*   ⚠️ **generateObjectService Caution**: Be aware of potential reliability issues with `generateObjectService` across different providers and complex schemas. Prefer `generateTextService` + manual parsing as a more robust alternative for structured data needs in PRD parsing.
*   ⚠️ **PRD Parsing Only**: Remember that AI services are exclusively for PRD parsing - do not use for any other task management operations.
